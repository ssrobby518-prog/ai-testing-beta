#!/usr/bin/env python3
"""
TSAR-RAPTOR Integrated System - å®Œæ•´äººçœ¼è¼”åŠ©å­¸ç¿’ç³»çµ±
é›†æˆ AIæª¢æ¸¬ + äººå·¥æ¨™è¨» + æŒçºŒè¨“ç·´

æ•´åˆæµç¨‹:
1. é‹è¡Œ TSAR-RAPTOR AI æª¢æ¸¬
2. è­˜åˆ¥ GRAY_ZONE è¦–é »ï¼ˆ20-60% AIæ¦‚ç‡ï¼‰
3. åŠ å…¥äººå·¥æ¨™è¨»ä½‡åˆ—
4. äººå·¥æ¨™è¨»ï¼ˆå¯é¸ï¼‰
5. æª¢æŸ¥æ˜¯å¦é”åˆ°é‡è¨“ç·´é–¾å€¼
6. è‡ªå‹•é‡è¨“ç·´ä¸¦éƒ¨ç½²æ”¹é€²æ¨¡å‹

è¨­è¨ˆåŸå‰‡:
- ç¬¬ä¸€æ€§åŸç†: ç‰©ç†ç‰¹æ€§ + äººé¡æ™ºæ…§é›™é‡é©—è­‰
- æ²™çš‡ç‚¸å½ˆ: ä¸‰éšæ®µç´šè¯ + 97%ç‰©ç†ç´”åº¦
- çŒ›ç¦½3: ç°¡ç´„é«˜æ•ˆï¼ŒæŒçºŒè¿­ä»£
"""

import os
import sys
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Tuple
import time

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from autotesting_v3 import TSARRaptorDetector, DetectionResult
from core.human_annotator import HumanAnnotator
from core.continuous_trainer import ContinuousTrainer

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class TSARRaptorIntegratedSystem:
    """TSAR-RAPTOR é›†æˆç³»çµ±"""

    def __init__(
        self,
        enable_human_annotation: bool = True,
        annotator_id: str = "default",
        auto_retrain: bool = True
    ):
        """
        Args:
            enable_human_annotation: å•Ÿç”¨äººå·¥æ¨™è¨»
            annotator_id: æ¨™è¨»è€…ID
            auto_retrain: è‡ªå‹•é‡è¨“ç·´
        """
        self.detector = TSARRaptorDetector()
        self.annotator = HumanAnnotator(annotator_id) if enable_human_annotation else None
        self.trainer = ContinuousTrainer() if auto_retrain else None
        self.enable_human_annotation = enable_human_annotation
        self.auto_retrain = auto_retrain

        logger.info("TSAR-RAPTOR é›†æˆç³»çµ±åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  â€¢ äººå·¥æ¨™è¨»: {'å•Ÿç”¨' if enable_human_annotation else 'ç¦ç”¨'}")
        logger.info(f"  â€¢ è‡ªå‹•é‡è¨“ç·´: {'å•Ÿç”¨' if auto_retrain else 'ç¦ç”¨'}")

    def process_videos(
        self,
        video_paths: List[str],
        annotate_gray_zone: bool = True
    ) -> Tuple[List[DetectionResult], int]:
        """
        è™•ç†è¦–é »åˆ—è¡¨ï¼Œå®Œæ•´é›†æˆæµç¨‹

        Args:
            video_paths: è¦–é »è·¯å¾‘åˆ—è¡¨
            annotate_gray_zone: æ˜¯å¦æ¨™è¨»ç°è‰²åœ°å¸¶è¦–é »

        Returns:
            (æª¢æ¸¬çµæœåˆ—è¡¨, æ¨™è¨»å®Œæˆæ•¸é‡)
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"TSAR-RAPTOR é›†æˆç³»çµ±é–‹å§‹è™•ç† {len(video_paths)} å€‹è¦–é »")
        logger.info(f"{'='*80}\n")

        # Phase 1: AI æª¢æ¸¬
        logger.info("Phase 1: TSAR-RAPTOR AI æª¢æ¸¬...")
        results = []
        gray_zone_videos = []

        for i, video_path in enumerate(video_paths, 1):
            logger.info(f"[{i}/{len(video_paths)}] æª¢æ¸¬: {os.path.basename(video_path)}")

            try:
                result = self.detector.detect(video_path)
                results.append(result)

                # è­˜åˆ¥ç°è‰²åœ°å¸¶
                if result.needs_human_review():
                    gray_zone_videos.append((video_path, result))
                    logger.info(f"  âš ï¸  GRAY_ZONE: AI_P={result.ai_probability:.1f}%, éœ€è¦äººå·¥å¾©å¯©")
                elif result.ai_probability >= 60:
                    logger.info(f"  ğŸš« BLOCK: AI_P={result.ai_probability:.1f}%")
                else:
                    logger.info(f"  âœ… PASS: AI_P={result.ai_probability:.1f}%")

            except Exception as e:
                logger.error(f"  âŒ æª¢æ¸¬å¤±æ•—: {e}")
                continue

        # çµ±è¨ˆ Phase 1 çµæœ
        self._show_detection_summary(results, gray_zone_videos)

        # Phase 2: äººå·¥æ¨™è¨»ï¼ˆå¯é¸ï¼‰
        annotations_completed = 0
        if self.enable_human_annotation and annotate_gray_zone and gray_zone_videos:
            logger.info(f"\nPhase 2: äººå·¥æ¨™è¨»ç°è‰²åœ°å¸¶è¦–é »...")
            annotations_completed = self._annotate_gray_zone(gray_zone_videos)

        # Phase 3: è‡ªå‹•é‡è¨“ç·´ï¼ˆå¯é¸ï¼‰
        if self.auto_retrain and self.trainer:
            logger.info(f"\nPhase 3: æª¢æŸ¥é‡è¨“ç·´æ¢ä»¶...")
            self.trainer.check_and_retrain(force=False)

        logger.info(f"\n{'='*80}")
        logger.info(f"TSAR-RAPTOR é›†æˆç³»çµ±è™•ç†å®Œæˆ")
        logger.info(f"{'='*80}\n")

        return results, annotations_completed

    def _show_detection_summary(
        self,
        results: List[DetectionResult],
        gray_zone_videos: List[Tuple[str, DetectionResult]]
    ):
        """é¡¯ç¤ºæª¢æ¸¬æ‘˜è¦"""
        total = len(results)
        gray_zone = len(gray_zone_videos)
        blocked = sum(1 for r in results if r.ai_probability >= 60)
        passed = sum(1 for r in results if r.ai_probability < 20)
        flagged = total - blocked - passed

        print(f"\n{'â”€'*80}")
        print(f"Phase 1 æª¢æ¸¬æ‘˜è¦:")
        print(f"  â€¢ ç¸½è¨ˆ: {total} å€‹è¦–é »")
        print(f"  â€¢ ğŸš« BLOCK (AI_P >= 60%): {blocked}")
        print(f"  â€¢ ğŸš© FLAG (20% < AI_P < 60%): {flagged}")
        print(f"  â€¢ âœ… PASS (AI_P < 20%): {passed}")
        print(f"  â€¢ âš ï¸  éœ€äººå·¥å¾©å¯©: {gray_zone}")
        print(f"{'â”€'*80}\n")

    def _annotate_gray_zone(
        self,
        gray_zone_videos: List[Tuple[str, DetectionResult]]
    ) -> int:
        """æ¨™è¨»ç°è‰²åœ°å¸¶è¦–é »"""
        if not self.annotator:
            logger.warning("äººå·¥æ¨™è¨»å™¨æœªå•Ÿç”¨")
            return 0

        print(f"\n{'='*80}")
        print(f"ç™¼ç¾ {len(gray_zone_videos)} å€‹ç°è‰²åœ°å¸¶è¦–é »éœ€è¦äººå·¥å¾©å¯©")
        print(f"{'='*80}\n")

        # è©¢å•æ˜¯å¦é€²è¡Œæ¨™è¨»
        response = input(f"æ˜¯å¦é–‹å§‹äººå·¥æ¨™è¨»ï¼Ÿ(y/nï¼Œé»˜èªn): ").lower().strip()
        if response != 'y':
            logger.info("è·³éäººå·¥æ¨™è¨»")
            return 0

        # æº–å‚™æ¨™è¨»æ•¸æ“š
        annotation_data = []
        for video_path, result in gray_zone_videos:
            ai_result = {
                'ai_probability': result.ai_probability,
                'confidence': result.confidence,
                'top_reasons': result.top_reasons
            }
            annotation_data.append((video_path, ai_result))

        # æ‰¹é‡æ¨™è¨»
        completed = self.annotator.batch_annotate(annotation_data)

        logger.info(f"âœ… å®Œæˆ {completed} å€‹è¦–é »çš„äººå·¥æ¨™è¨»")
        return completed

    def show_system_status(self):
        """é¡¯ç¤ºç³»çµ±ç‹€æ…‹"""
        print(f"\n{'='*80}")
        print(f"{'TSAR-RAPTOR é›†æˆç³»çµ±ç‹€æ…‹'.center(80)}")
        print(f"{'='*80}\n")

        # äººå·¥æ¨™è¨»çµ±è¨ˆ
        if self.annotator:
            self.annotator.show_statistics()

        # æŒçºŒè¨“ç·´ç‹€æ…‹
        if self.trainer:
            self.trainer.show_training_status()

    def force_retrain(self):
        """å¼·åˆ¶é‡è¨“ç·´"""
        if not self.trainer:
            logger.error("æŒçºŒè¨“ç·´å™¨æœªå•Ÿç”¨")
            return

        logger.info("å¼·åˆ¶é‡è¨“ç·´...")
        new_model_path = self.trainer.check_and_retrain(force=True)

        if new_model_path:
            logger.info(f"âœ… è¨“ç·´å®Œæˆ: {new_model_path}")
        else:
            logger.warning("è¨“ç·´å¤±æ•—æˆ–ç„¡å¯ç”¨æ•¸æ“š")


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(
        description="TSAR-RAPTOR é›†æˆç³»çµ± - AIæª¢æ¸¬ + äººçœ¼è¼”åŠ©å­¸ç¿’"
    )
    parser.add_argument(
        '--input',
        type=str,
        default='input',
        help='è¼¸å…¥ç›®éŒ„æˆ–è¦–é »æ–‡ä»¶è·¯å¾‘'
    )
    parser.add_argument(
        '--no-annotation',
        action='store_true',
        help='ç¦ç”¨äººå·¥æ¨™è¨»'
    )
    parser.add_argument(
        '--no-retrain',
        action='store_true',
        help='ç¦ç”¨è‡ªå‹•é‡è¨“ç·´'
    )
    parser.add_argument(
        '--status',
        action='store_true',
        help='åªé¡¯ç¤ºç³»çµ±ç‹€æ…‹'
    )
    parser.add_argument(
        '--force-retrain',
        action='store_true',
        help='å¼·åˆ¶é‡è¨“ç·´æ¨¡å‹'
    )
    parser.add_argument(
        '--annotator-id',
        type=str,
        default='default',
        help='æ¨™è¨»è€…ID'
    )

    args = parser.parse_args()

    # å‰µå»ºé›†æˆç³»çµ±
    system = TSARRaptorIntegratedSystem(
        enable_human_annotation=not args.no_annotation,
        annotator_id=args.annotator_id,
        auto_retrain=not args.no_retrain
    )

    # åªé¡¯ç¤ºç‹€æ…‹
    if args.status:
        system.show_system_status()
        return

    # å¼·åˆ¶é‡è¨“ç·´
    if args.force_retrain:
        system.force_retrain()
        return

    # ç²å–è¦–é »åˆ—è¡¨
    input_path = Path(args.input)
    if input_path.is_file():
        video_paths = [str(input_path)]
    elif input_path.is_dir():
        video_paths = [
            str(p) for p in input_path.glob('*.mp4')
        ]
    else:
        logger.error(f"ç„¡æ•ˆçš„è¼¸å…¥è·¯å¾‘: {input_path}")
        return

    if not video_paths:
        logger.error(f"æœªæ‰¾åˆ°è¦–é »æ–‡ä»¶: {input_path}")
        return

    # è™•ç†è¦–é »
    start_time = time.time()
    results, annotations = system.process_videos(
        video_paths,
        annotate_gray_zone=not args.no_annotation
    )
    elapsed = time.time() - start_time

    # æœ€çµ‚çµ±è¨ˆ
    print(f"\n{'='*80}")
    print(f"TSAR-RAPTOR é›†æˆç³»çµ±åŸ·è¡Œçµ±è¨ˆ:")
    print(f"  â€¢ è™•ç†è¦–é »: {len(video_paths)}")
    print(f"  â€¢ å®Œæˆæ¨™è¨»: {annotations}")
    print(f"  â€¢ åŸ·è¡Œæ™‚é–“: {elapsed:.2f} ç§’")
    print(f"  â€¢ å¹³å‡é€Ÿåº¦: {elapsed/len(video_paths):.2f} ç§’/è¦–é »")
    print(f"{'='*80}\n")

    # é¡¯ç¤ºç³»çµ±ç‹€æ…‹
    system.show_system_status()


if __name__ == "__main__":
    main()
