#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TSAR-RAPTOR Layer 2 è‡ªå‹•åŒ–æµæ°´ç·š
AIä¸»å°è‡ªå‹•åŒ– - æ‰¹é‡ä¸‹è¼‰ â†’ AIæª¢æ¸¬ â†’ è‡ªå‹•åˆ†é¡ â†’ äººå·¥å¾©å¯©

è¨­è¨ˆåŸå‰‡:
- ç¬¬ä¸€æ€§åŸç†: AIä¸»å°ï¼Œäººé¡è¼”åŠ©
- æ²™çš‡ç‚¸å½ˆ: æµ·é‡æ•¸æ“šï¼Œè‡ªå‹•åŒ–è™•ç†
- çŒ›ç¦½3: ä¸€éµåŸ·è¡Œï¼Œå…¨è‡ªå‹•æµæ°´ç·š

å®Œæ•´æµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: AIä¸»å°è‡ªå‹•åŒ–æµæ°´ç·š                                 â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ 1. æ‰¹é‡ä¸‹è¼‰TikTokè¦–é »ï¼ˆ2000å€‹ï¼‰                             â”‚
â”‚ 2. AIæª¢æ¸¬æ¨¡çµ„è‡ªå‹•åˆ†é¡ï¼ˆreal/ai/not sure/é›»å½±å‹•ç•«ï¼‰          â”‚
â”‚ 3. ç”Ÿæˆ Excel Dï¼ˆåˆ†é¡çµæœ + ç‰¹å¾µè¨˜éŒ„ï¼‰                      â”‚
â”‚ 4. è‡ªå‹•ç§»å‹•æ–‡ä»¶åˆ°å°æ‡‰æ–‡ä»¶å¤¾                                 â”‚
â”‚ 5. å¾ "not sure" æ–‡ä»¶å¤¾æå–ä¸ç¢ºå®šè¦–é »                       â”‚
â”‚ 6. æœ¬åœ°Tinderå¾©å¯©ç³»çµ±                                       â”‚
â”‚ 7. å¾©å¯©å¾Œè‡ªå‹•ç§»å‹•åˆ°æ­£ç¢ºåˆ†é¡æ–‡ä»¶å¤¾                           â”‚
â”‚ 8. æ›´æ–° Excel D äººå·¥å¾©å¯©çµæœ                                â”‚
â”‚ â†» å¾ªç’°å„ªåŒ– â†’ 99% æº–ç¢ºç‡                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import sys
from pathlib import Path
import logging
from typing import Dict, List
import argparse

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å°å…¥å„çµ„ä»¶
from mass_downloader.url_scraper import TikTokURLScraper
from mass_downloader.mass_downloader import TikTokMassDownloader
from ai_classifier.ai_detector import AIDetectionClassifier
from ai_classifier.excel_d_generator import ExcelDGenerator
from file_organizer.auto_classifier import FileAutoClassifier
from local_reviewer.review_interface import LocalReviewer, load_uncertain_videos_from_folder

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class Layer2Pipeline:
    """Layer 2 è‡ªå‹•åŒ–æµæ°´ç·šç¸½æ§"""

    def __init__(
        self,
        url_list_file: str = None,
        download_dir: str = "../../tiktok videos download",
        target_count: int = 2000,
        max_workers_download: int = 8,
        max_workers_detect: int = 4
    ):
        """
        Args:
            url_list_file: URLåˆ—è¡¨æ–‡ä»¶è·¯å¾‘
            download_dir: ä¸‹è¼‰ç›®éŒ„ï¼ˆä¹Ÿæ˜¯åˆ†é¡æ ¹ç›®éŒ„ï¼‰
            target_count: ç›®æ¨™ä¸‹è¼‰æ•¸é‡
            max_workers_download: ä¸‹è¼‰ä¸¦è¡Œæ•¸
            max_workers_detect: æª¢æ¸¬ä¸¦è¡Œæ•¸
        """
        self.url_list_file = url_list_file
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(parents=True, exist_ok=True)
        self.target_count = target_count
        self.max_workers_download = max_workers_download
        self.max_workers_detect = max_workers_detect

        # æ–‡ä»¶è·¯å¾‘
        self.data_dir = self.download_dir / "data"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.excel_d_path = self.data_dir / "excel_d_detection_results.xlsx"

        logger.info("Layer 2 æµæ°´ç·šåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  â€¢ ä¸‹è¼‰ç›®éŒ„: {self.download_dir}")
        logger.info(f"  â€¢ ç›®æ¨™æ•¸é‡: {target_count}")
        logger.info(f"  â€¢ Excel D: {self.excel_d_path}")

    def run_full_pipeline(
        self,
        skip_download: bool = False,
        skip_detection: bool = False,
        skip_classification: bool = False,
        skip_review: bool = False
    ) -> Dict:
        """
        é‹è¡Œå®Œæ•´ Layer 2 æµæ°´ç·š

        Args:
            skip_download: è·³éä¸‹è¼‰æ­¥é©Ÿ
            skip_detection: è·³éAIæª¢æ¸¬æ­¥é©Ÿ
            skip_classification: è·³éæ–‡ä»¶åˆ†é¡æ­¥é©Ÿ
            skip_review: è·³éäººå·¥å¾©å¯©æ­¥é©Ÿ

        Returns:
            åŸ·è¡Œçµ±è¨ˆ
        """
        logger.info(f"\n{'='*100}")
        logger.info("ğŸš€ TSAR-RAPTOR Layer 2 AIä¸»å°è‡ªå‹•åŒ–æµæ°´ç·š - å•Ÿå‹•")
        logger.info(f"{'='*100}\n")

        stats = {}

        # Step 1: æ‰¹é‡ä¸‹è¼‰è¦–é »
        if not skip_download:
            logger.info(f"ğŸ“¥ [Step 1/6] æ‰¹é‡ä¸‹è¼‰TikTokè¦–é »...")
            download_stats = self._batch_download()
            stats['download'] = download_stats
        else:
            logger.info("â­ï¸  è·³éä¸‹è¼‰æ­¥é©Ÿ")

        # Step 2: AIæª¢æ¸¬åˆ†é¡
        if not skip_detection:
            logger.info(f"\nğŸ¤– [Step 2/6] AIæª¢æ¸¬æ¨¡çµ„è‡ªå‹•åˆ†é¡...")
            detection_results = self._ai_detection()
            stats['detection'] = {
                'total': len(detection_results),
                'real': sum(1 for r in detection_results if r['classification'] == 'REAL'),
                'ai': sum(1 for r in detection_results if r['classification'] == 'AI'),
                'not_sure': sum(1 for r in detection_results if r['classification'] == 'NOT_SURE'),
                'movie': sum(1 for r in detection_results if r['classification'] == 'é›»å½±å‹•ç•«')
            }
        else:
            logger.info("â­ï¸  è·³éAIæª¢æ¸¬æ­¥é©Ÿ")
            detection_results = []

        # Step 3: ç”Ÿæˆ Excel D
        if detection_results:
            logger.info(f"\nğŸ“Š [Step 3/6] ç”Ÿæˆ Excel D...")
            df_excel_d = self._generate_excel_d(detection_results)
            stats['excel_d'] = {'rows': len(df_excel_d)}
        else:
            logger.info("â­ï¸  ç„¡æª¢æ¸¬çµæœï¼Œè·³é Excel D ç”Ÿæˆ")

        # Step 4: è‡ªå‹•æ–‡ä»¶åˆ†é¡
        if not skip_classification and detection_results:
            logger.info(f"\nğŸ“¦ [Step 4/6] è‡ªå‹•ç§»å‹•æ–‡ä»¶åˆ°åˆ†é¡æ–‡ä»¶å¤¾...")
            classification_stats = self._classify_files(detection_results)
            stats['classification'] = classification_stats
        else:
            logger.info("â­ï¸  è·³éæ–‡ä»¶åˆ†é¡æ­¥é©Ÿ")

        # Step 5: åŠ è¼‰ not sure è¦–é »
        logger.info(f"\nğŸ” [Step 5/6] åŠ è¼‰ä¸ç¢ºå®šè¦–é »...")
        not_sure_folder = self.download_dir / "not sure"
        uncertain_videos = load_uncertain_videos_from_folder(str(not_sure_folder))
        stats['uncertain_count'] = len(uncertain_videos)

        if not uncertain_videos:
            logger.info("âœ… æ²’æœ‰ä¸ç¢ºå®šè¦–é »ï¼Œç„¡éœ€å¾©å¯©")
            skip_review = True

        # Step 6: æœ¬åœ°Tinderå¾©å¯©
        if not skip_review and uncertain_videos:
            logger.info(f"\nğŸ‘ï¸  [Step 6/6] æœ¬åœ°Tinderå¾©å¯© ({len(uncertain_videos)} å€‹è¦–é »)...")
            review_stats = self._review_uncertain_videos(uncertain_videos)
            stats['review'] = review_stats
        else:
            logger.info("â­ï¸  è·³éäººå·¥å¾©å¯©æ­¥é©Ÿ")

        # æœ€çµ‚çµ±è¨ˆ
        logger.info(f"\n{'='*100}")
        logger.info("ğŸ‰ Layer 2 æµæ°´ç·šåŸ·è¡Œå®Œç•¢ï¼")
        logger.info(f"{'='*100}")
        if 'download' in stats:
            logger.info(f"  â€¢ ä¸‹è¼‰è¦–é »: {stats['download'].get('success', 0)} æˆåŠŸ")
        if 'detection' in stats:
            logger.info(f"  â€¢ AIæª¢æ¸¬: {stats['detection']['total']} å€‹è¦–é »")
            logger.info(f"    - REAL: {stats['detection']['real']}")
            logger.info(f"    - AI: {stats['detection']['ai']}")
            logger.info(f"    - NOT_SURE: {stats['detection']['not_sure']}")
            logger.info(f"    - é›»å½±å‹•ç•«: {stats['detection']['movie']}")
        if 'classification' in stats:
            logger.info(f"  â€¢ æ–‡ä»¶åˆ†é¡: {stats['classification'].get('moved', 0)} å€‹å·²ç§»å‹•")
        if 'review' in stats:
            logger.info(f"  â€¢ äººå·¥å¾©å¯©: {stats['review'].get('reviewed', 0)} å€‹å·²å¾©å¯©")
        logger.info(f"{'='*100}\n")

        return stats

    def _batch_download(self) -> Dict:
        """Step 1: æ‰¹é‡ä¸‹è¼‰è¦–é »"""
        if not self.url_list_file or not Path(self.url_list_file).exists():
            logger.warning(f"âš ï¸  URLåˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨: {self.url_list_file}")
            logger.warning("   ä½¿ç”¨ url_scraper.py ç”ŸæˆURLåˆ—è¡¨")
            return {'success': 0, 'failed': 0}

        # å‰µå»ºä¸‹è¼‰å™¨
        downloader = TikTokMassDownloader(
            url_list_file=self.url_list_file,
            download_dir=str(self.download_dir),
            max_workers=self.max_workers_download,
            target_count=self.target_count
        )

        # åŸ·è¡Œä¸‹è¼‰
        stats = downloader.batch_download()
        return stats

    def _ai_detection(self) -> List[Dict]:
        """Step 2: AIæª¢æ¸¬åˆ†é¡"""
        # å‰µå»ºæª¢æ¸¬å™¨
        detector = AIDetectionClassifier(
            video_dir=str(self.download_dir),
            max_workers=self.max_workers_detect
        )

        # æ‰¹é‡æª¢æ¸¬
        results = detector.batch_detect()
        return results

    def _generate_excel_d(self, detection_results: List[Dict]) -> "pd.DataFrame":
        """Step 3: ç”Ÿæˆ Excel D"""
        # å‰µå»ºç”Ÿæˆå™¨
        generator = ExcelDGenerator(
            video_dir=str(self.download_dir),
            output_excel_d=str(self.excel_d_path)
        )

        # ç”Ÿæˆ Excel D
        df = generator.generate_from_detection_results(detection_results)
        return df

    def _classify_files(self, detection_results: List[Dict]) -> Dict:
        """Step 4: è‡ªå‹•æ–‡ä»¶åˆ†é¡"""
        # å‰µå»ºåˆ†é¡å™¨
        classifier = FileAutoClassifier(
            source_dir=str(self.download_dir),
            base_output_dir=str(self.download_dir)
        )

        # åŸ·è¡Œåˆ†é¡
        stats = classifier.classify_from_detection_results(
            detection_results,
            move_files=True
        )
        return stats

    def _review_uncertain_videos(self, uncertain_videos: List[str]) -> Dict:
        """Step 6: æœ¬åœ°Tinderå¾©å¯©"""
        # å‰µå»ºå¾©å¯©å™¨
        reviewer = LocalReviewer(
            uncertain_videos=uncertain_videos,
            output_csv=str(self.data_dir / "layer2_review_results.csv"),
            base_output_dir=str(self.download_dir),
            excel_d_path=str(self.excel_d_path),
            auto_move_files=True
        )

        # åŸ·è¡Œå¾©å¯©
        stats = reviewer.batch_review()
        return stats


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description="Layer 2 AIä¸»å°è‡ªå‹•åŒ–æµæ°´ç·š")

    # åŸºæœ¬åƒæ•¸
    parser.add_argument(
        '--url-list',
        type=str,
        help='URLåˆ—è¡¨æ–‡ä»¶è·¯å¾‘'
    )
    parser.add_argument(
        '--download-dir',
        type=str,
        default='../../tiktok videos download',
        help='ä¸‹è¼‰ç›®éŒ„'
    )
    parser.add_argument(
        '--target',
        type=int,
        default=2000,
        help='ç›®æ¨™ä¸‹è¼‰æ•¸é‡'
    )
    parser.add_argument(
        '--download-workers',
        type=int,
        default=8,
        help='ä¸‹è¼‰ä¸¦è¡Œæ•¸'
    )
    parser.add_argument(
        '--detect-workers',
        type=int,
        default=4,
        help='æª¢æ¸¬ä¸¦è¡Œæ•¸'
    )

    # æµç¨‹æ§åˆ¶
    parser.add_argument(
        '--skip-download',
        action='store_true',
        help='è·³éä¸‹è¼‰æ­¥é©Ÿ'
    )
    parser.add_argument(
        '--skip-detection',
        action='store_true',
        help='è·³éAIæª¢æ¸¬æ­¥é©Ÿ'
    )
    parser.add_argument(
        '--skip-classification',
        action='store_true',
        help='è·³éæ–‡ä»¶åˆ†é¡æ­¥é©Ÿ'
    )
    parser.add_argument(
        '--skip-review',
        action='store_true',
        help='è·³éäººå·¥å¾©å¯©æ­¥é©Ÿ'
    )

    args = parser.parse_args()

    # å‰µå»ºæµæ°´ç·š
    pipeline = Layer2Pipeline(
        url_list_file=args.url_list,
        download_dir=args.download_dir,
        target_count=args.target,
        max_workers_download=args.download_workers,
        max_workers_detect=args.detect_workers
    )

    # åŸ·è¡Œå®Œæ•´æµæ°´ç·š
    stats = pipeline.run_full_pipeline(
        skip_download=args.skip_download,
        skip_detection=args.skip_detection,
        skip_classification=args.skip_classification,
        skip_review=args.skip_review
    )

    print(f"\nâœ… Layer 2 æµæ°´ç·šåŸ·è¡Œå®Œæˆï¼")


if __name__ == "__main__":
    main()
