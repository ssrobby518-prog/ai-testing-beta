#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TSAR-RAPTOR Self-Learning Pipeline
å®Œæ•´è‡ªæˆ‘å­¸ç¿’æµæ°´ç·š - æ•´åˆå…©å±¤ç³»çµ±

è¨­è¨ˆåŸå‰‡:
- ç¬¬ä¸€æ€§åŸç†: æ•¸æ“š â†’ åˆ†æ â†’ å„ªåŒ– â†’ å¾ªç’°
- æ²™çš‡ç‚¸å½ˆ: ç´šè¯å­¸ç¿’ï¼ŒæŒ‡æ•¸å¢é•·
- çŒ›ç¦½3: å…¨è‡ªå‹•åŒ–ï¼Œé›¶äººå·¥å¹²é ï¼ˆé™¤æ¨™è¨»å¤–ï¼‰

å®Œæ•´æµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 1: äººå·¥ä¸»å°æ¨™è¨»                                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ 1. Chromeæ“´å±•æ¨™è¨» â†’ Excel A                                 â”‚
â”‚ 2. æ‰¹é‡ä¸‹è¼‰è¦–é »                                             â”‚
â”‚ 3. ç‰¹å¾µæå– â†’ Excel B                                       â”‚
â”‚ 4. å¤§æ•¸æ“šåˆ†æ â†’ Excel C                                     â”‚
â”‚ 5. æ¨¡çµ„è‡ªå‹•å„ªåŒ–                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ å‡ç´šAIæ¨¡çµ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer 2: AIä¸»å°è‡ªå‹•åŒ–                                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ 1. è‡ªå‹•ä¸‹è¼‰2000å€‹è¦–é »                                       â”‚
â”‚ 2. AIæª¢æ¸¬æ¨¡çµ„åˆ¤å®š                                           â”‚
â”‚ 3. æå–ä¸ç¢ºå®šè¦–é »                                           â”‚
â”‚ 4. æœ¬åœ°Tinderå¾©å¯©                                           â”‚
â”‚ 5. æŒçºŒè¨“ç·´å„ªåŒ–                                             â”‚
â”‚ â†» å¾ªç’°                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""

import sys
from pathlib import Path
import logging
import argparse
from typing import Dict

# æ·»åŠ é …ç›®è·¯å¾‘
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# å°å…¥å„çµ„ä»¶
from downloader.tiktok_downloader import TikTokDownloader
from analyzer.feature_extractor import FeatureExtractor
from analyzer.big_data_analyzer import BigDataAnalyzer
from auto_reconstructor.module_optimizer import ModuleOptimizer
from local_reviewer.review_interface import LocalReviewer, load_uncertain_videos_from_detection_results

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class SelfLearningPipeline:
    """è‡ªæˆ‘å­¸ç¿’æµæ°´ç·šç¸½æ§"""

    def __init__(
        self,
        excel_a_path: str,
        video_dir: str = "../data/tiktok_videos",
        data_dir: str = "../data/tiktok_labels"
    ):
        """
        Args:
            excel_a_path: Excel A è·¯å¾‘ï¼ˆäººå·¥æ¨™è¨»æ•¸æ“šï¼‰
            video_dir: è¦–é »ä¸‹è¼‰ç›®éŒ„
            data_dir: æ•¸æ“šè¼¸å‡ºç›®éŒ„
        """
        self.excel_a_path = Path(excel_a_path)
        self.video_dir = Path(video_dir)
        self.data_dir = Path(data_dir)

        self.video_dir.mkdir(parents=True, exist_ok=True)
        self.data_dir.mkdir(parents=True, exist_ok=True)

        # æ–‡ä»¶è·¯å¾‘
        self.excel_b_path = self.data_dir / "excel_b_features.xlsx"
        self.excel_c_path = self.data_dir / "excel_c_analysis.xlsx"
        self.optimized_config_path = self.data_dir / "optimized_config.json"

        logger.info("è‡ªæˆ‘å­¸ç¿’æµæ°´ç·šåˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  â€¢ Excel A: {self.excel_a_path}")
        logger.info(f"  â€¢ è¦–é »ç›®éŒ„: {self.video_dir}")
        logger.info(f"  â€¢ æ•¸æ“šç›®éŒ„: {self.data_dir}")

    def run_layer1_pipeline(self) -> Dict:
        """
        é‹è¡Œç¬¬ä¸€å±¤æµæ°´ç·šï¼ˆäººå·¥ä¸»å°ï¼‰

        æµç¨‹:
        1. æª¢æŸ¥ Excel A æ˜¯å¦æœ‰æ–°æ¨™è¨»
        2. æ‰¹é‡ä¸‹è¼‰è¦–é »
        3. ç‰¹å¾µæå– â†’ Excel B
        4. å¤§æ•¸æ“šåˆ†æ â†’ Excel C
        5. æ¨¡çµ„å„ªåŒ–

        Returns:
            åŸ·è¡Œçµ±è¨ˆ
        """
        logger.info(f"\n{'='*80}")
        logger.info("Layer 1: äººå·¥ä¸»å°æ¨™è¨»æµæ°´ç·š")
        logger.info(f"{'='*80}\n")

        stats = {}

        # Step 1: æª¢æŸ¥ Excel A
        if not self.excel_a_path.exists():
            logger.error(f"âŒ Excel A ä¸å­˜åœ¨: {self.excel_a_path}")
            logger.error("   è«‹å…ˆä½¿ç”¨ Chrome æ“´å±•é€²è¡Œæ¨™è¨»")
            return {}

        # Step 2: æ‰¹é‡ä¸‹è¼‰è¦–é »
        logger.info("ğŸ“¥ [Step 1/4] æ‰¹é‡ä¸‹è¼‰è¦–é »...")
        downloader = TikTokDownloader(
            excel_a_path=str(self.excel_a_path),
            download_dir=str(self.video_dir),
            max_workers=4
        )
        download_stats = downloader.download_from_excel_a(exclude_labels=['exclude'])
        stats['download'] = download_stats

        # Step 3: ç‰¹å¾µæå–
        logger.info("\nğŸ”¬ [Step 2/4] ç‰¹å¾µæå–...")
        extractor = FeatureExtractor(
            video_dir=str(self.video_dir),
            output_excel_b=str(self.excel_b_path),
            max_workers=4,
            sample_frames=30
        )
        df_features = extractor.batch_extract()
        stats['features'] = {'total': len(df_features)}

        # Step 4: å¤§æ•¸æ“šåˆ†æ
        logger.info("\nğŸ“Š [Step 3/4] å¤§æ•¸æ“šåˆ†æ...")
        analyzer = BigDataAnalyzer(
            excel_b_path=str(self.excel_b_path),
            output_excel_c=str(self.excel_c_path)
        )
        analysis_results = analyzer.analyze()
        stats['analysis'] = {'features_analyzed': len(analysis_results.get('ranked_features', []))}

        # Step 5: æ¨¡çµ„å„ªåŒ–
        logger.info("\nâš™ï¸  [Step 4/4] æ¨¡çµ„è‡ªå‹•å„ªåŒ–...")
        optimizer = ModuleOptimizer(
            excel_c_path=str(self.excel_c_path),
            config_output=str(self.optimized_config_path)
        )
        optimized_config = optimizer.optimize()
        stats['optimization'] = {'modules_optimized': len(optimized_config.get('module_weights', {}))}

        logger.info(f"\n{'='*80}")
        logger.info("âœ… Layer 1 æµæ°´ç·šå®Œæˆï¼")
        logger.info(f"{'='*80}")
        logger.info(f"  â€¢ ä¸‹è¼‰è¦–é »: {download_stats['success']} æˆåŠŸ, {download_stats['failed']} å¤±æ•—")
        logger.info(f"  â€¢ æå–ç‰¹å¾µ: {len(df_features)} å€‹è¦–é »")
        logger.info(f"  â€¢ åˆ†æç‰¹å¾µ: {len(analysis_results.get('ranked_features', []))} å€‹ç‰¹å¾µ")
        logger.info(f"  â€¢ å„ªåŒ–æ¨¡çµ„: {len(optimized_config.get('module_weights', {}))} å€‹æ¨¡çµ„")
        logger.info(f"{'='*80}\n")

        return stats

    def run_layer2_pipeline(
        self,
        detection_results_csv: str,
        enable_review: bool = True
    ) -> Dict:
        """
        é‹è¡Œç¬¬äºŒå±¤æµæ°´ç·šï¼ˆAIä¸»å°è‡ªå‹•åŒ–ï¼‰

        æµç¨‹:
        1. è®€å–AIæª¢æ¸¬çµæœ
        2. æå–ä¸ç¢ºå®šè¦–é »
        3. æœ¬åœ°Tinderå¾©å¯©
        4. æŒçºŒè¨“ç·´ï¼ˆæ•´åˆåˆ°autotesting_integrated.pyï¼‰

        Args:
            detection_results_csv: AIæª¢æ¸¬çµæœCSV
            enable_review: æ˜¯å¦å•Ÿç”¨äººå·¥å¾©å¯©

        Returns:
            åŸ·è¡Œçµ±è¨ˆ
        """
        logger.info(f"\n{'='*80}")
        logger.info("Layer 2: AIä¸»å°è‡ªå‹•åŒ–æµæ°´ç·š")
        logger.info(f"{'='*80}\n")

        stats = {}

        # Step 1: åŠ è¼‰ä¸ç¢ºå®šè¦–é »
        logger.info("ğŸ“‹ [Step 1/2] åŠ è¼‰ä¸ç¢ºå®šè¦–é »...")
        uncertain_videos = load_uncertain_videos_from_detection_results(
            detection_results_csv,
            str(self.video_dir)
        )
        stats['uncertain_count'] = len(uncertain_videos)

        if not uncertain_videos:
            logger.info("âœ… æ²’æœ‰ä¸ç¢ºå®šè¦–é »ï¼Œç„¡éœ€å¾©å¯©")
            return stats

        # Step 2: æœ¬åœ°å¾©å¯©
        if enable_review:
            logger.info(f"\nğŸ‘ï¸  [Step 2/2] æœ¬åœ°Tinderå¾©å¯© ({len(uncertain_videos)} å€‹è¦–é »)...")
            reviewer = LocalReviewer(
                uncertain_videos=uncertain_videos,
                output_csv=str(self.data_dir / "layer2_review_results.csv")
            )
            review_stats = reviewer.batch_review()
            stats['review'] = review_stats
        else:
            logger.info("â­ï¸  è·³éäººå·¥å¾©å¯©ï¼ˆenable_review=Falseï¼‰")
            stats['review'] = {'skipped': True}

        logger.info(f"\n{'='*80}")
        logger.info("âœ… Layer 2 æµæ°´ç·šå®Œæˆï¼")
        logger.info(f"{'='*80}")
        if enable_review and 'review' in stats:
            logger.info(f"  â€¢ ä¸ç¢ºå®šè¦–é »: {stats['uncertain_count']}")
            logger.info(f"  â€¢ å·²å¾©å¯©: {stats['review'].get('reviewed', 0)}")
            logger.info(f"  â€¢ Real: {stats['review'].get('real', 0)}")
            logger.info(f"  â€¢ AI: {stats['review'].get('ai', 0)}")
        logger.info(f"{'='*80}\n")

        return stats

    def run_full_pipeline(
        self,
        run_layer1: bool = True,
        run_layer2: bool = False,
        detection_results_csv: str = None
    ) -> Dict:
        """
        é‹è¡Œå®Œæ•´æµæ°´ç·šï¼ˆå…©å±¤ï¼‰

        Args:
            run_layer1: æ˜¯å¦é‹è¡Œ Layer 1
            run_layer2: æ˜¯å¦é‹è¡Œ Layer 2
            detection_results_csv: AIæª¢æ¸¬çµæœCSVï¼ˆLayer 2 éœ€è¦ï¼‰

        Returns:
            å®Œæ•´åŸ·è¡Œçµ±è¨ˆ
        """
        logger.info(f"\n{'='*100}")
        logger.info("ğŸš€ TSAR-RAPTOR Self-Learning Pipeline - å•Ÿå‹•")
        logger.info(f"{'='*100}\n")

        full_stats = {}

        # Layer 1
        if run_layer1:
            layer1_stats = self.run_layer1_pipeline()
            full_stats['layer1'] = layer1_stats

        # Layer 2
        if run_layer2:
            if not detection_results_csv:
                logger.error("âŒ Layer 2 éœ€è¦æä¾› detection_results_csv")
            else:
                layer2_stats = self.run_layer2_pipeline(detection_results_csv)
                full_stats['layer2'] = layer2_stats

        logger.info(f"\n{'='*100}")
        logger.info("ğŸ‰ å®Œæ•´æµæ°´ç·šåŸ·è¡Œå®Œç•¢ï¼")
        logger.info(f"{'='*100}\n")

        return full_stats


def main():
    """ä¸»ç¨‹å¼"""
    parser = argparse.ArgumentParser(description="TSAR-RAPTOR è‡ªæˆ‘å­¸ç¿’æµæ°´ç·š")

    # åŸºæœ¬åƒæ•¸
    parser.add_argument(
        '--excel-a',
        type=str,
        default='../data/tiktok_labels/excel_a_labels_raw.xlsx',
        help='Excel A è·¯å¾‘ï¼ˆäººå·¥æ¨™è¨»æ•¸æ“šï¼‰'
    )
    parser.add_argument(
        '--video-dir',
        type=str,
        default='../data/tiktok_videos',
        help='è¦–é »ç›®éŒ„'
    )
    parser.add_argument(
        '--data-dir',
        type=str,
        default='../data/tiktok_labels',
        help='æ•¸æ“šç›®éŒ„'
    )

    # æµç¨‹æ§åˆ¶
    parser.add_argument(
        '--layer1',
        action='store_true',
        help='é‹è¡Œ Layer 1ï¼ˆäººå·¥ä¸»å°æ¨™è¨»æµæ°´ç·šï¼‰'
    )
    parser.add_argument(
        '--layer2',
        action='store_true',
        help='é‹è¡Œ Layer 2ï¼ˆAIä¸»å°è‡ªå‹•åŒ–æµæ°´ç·šï¼‰'
    )
    parser.add_argument(
        '--full',
        action='store_true',
        help='é‹è¡Œå®Œæ•´æµæ°´ç·šï¼ˆLayer 1 + Layer 2ï¼‰'
    )

    # Layer 2 åƒæ•¸
    parser.add_argument(
        '--detection-results',
        type=str,
        help='AIæª¢æ¸¬çµæœCSVï¼ˆLayer 2 éœ€è¦ï¼‰'
    )

    args = parser.parse_args()

    # å‰µå»ºæµæ°´ç·š
    pipeline = SelfLearningPipeline(
        excel_a_path=args.excel_a,
        video_dir=args.video_dir,
        data_dir=args.data_dir
    )

    # åŸ·è¡Œæµç¨‹
    if args.full:
        stats = pipeline.run_full_pipeline(
            run_layer1=True,
            run_layer2=True,
            detection_results_csv=args.detection_results
        )
    elif args.layer1:
        stats = pipeline.run_layer1_pipeline()
    elif args.layer2:
        if not args.detection_results:
            logger.error("âŒ Layer 2 éœ€è¦æä¾› --detection-results")
            return
        stats = pipeline.run_layer2_pipeline(args.detection_results)
    else:
        parser.print_help()
        print("\næç¤º: ä½¿ç”¨ --layer1, --layer2 æˆ– --full é¸æ“‡é‹è¡Œæ¨¡å¼")
        return

    print(f"\nâœ… æµæ°´ç·šåŸ·è¡Œå®Œæˆï¼")


if __name__ == "__main__":
    main()
