#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TSAR-RAPTOR TikTok Downloader
æ ¹æ“šExcel Aæ‰¹é‡ä¸‹è¼‰TikTokè¦–é »

è¨­è¨ˆåŸå‰‡:
- ç¬¬ä¸€æ€§åŸç†: å¢é‡ä¸‹è¼‰ï¼Œé¿å…é‡è¤‡
- æ²™çš‡ç‚¸å½ˆ: æ‰¹é‡ä¸¦è¡Œï¼Œæ¥µé€Ÿä¸‹è¼‰
- çŒ›ç¦½3: ç°¡ç´„æ¥å£ï¼Œè‡ªå‹•é‡è©¦

åŠŸèƒ½:
1. è®€å–Excel A (labels_raw.xlsx)
2. éæ¿¾éœ€è¦ä¸‹è¼‰çš„è¦–é »ï¼ˆæ’é™¤ exclude é¡åˆ¥ï¼‰
3. ä½¿ç”¨ yt-dlp æ‰¹é‡ä¸‹è¼‰
4. è‡ªå‹•é‡å‘½åï¼š{label}_{video_id}.mp4
5. ä¸‹è¼‰å¤±æ•—è‡ªå‹•é‡è©¦
"""

import subprocess
import pandas as pd
from pathlib import Path
import logging
from typing import List, Dict
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class TikTokDownloader:
    """TikTok è¦–é »æ‰¹é‡ä¸‹è¼‰å™¨"""

    def __init__(
        self,
        excel_a_path: str,
        download_dir: str = "downloaded_videos",
        max_workers: int = 4,
        retry_times: int = 3
    ):
        """
        Args:
            excel_a_path: Excel A è·¯å¾‘
            download_dir: ä¸‹è¼‰ç›®éŒ„
            max_workers: ä¸¦è¡Œä¸‹è¼‰æ•¸
            retry_times: å¤±æ•—é‡è©¦æ¬¡æ•¸
        """
        self.excel_a_path = Path(excel_a_path)
        self.download_dir = Path(download_dir)
        self.download_dir.mkdir(parents=True, exist_ok=True)
        self.max_workers = max_workers
        self.retry_times = retry_times

        logger.info("TikTokä¸‹è¼‰å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"  â€¢ Excel A: {self.excel_a_path}")
        logger.info(f"  â€¢ ä¸‹è¼‰ç›®éŒ„: {self.download_dir}")
        logger.info(f"  â€¢ ä¸¦è¡Œæ•¸: {self.max_workers}")

    def load_labels(self, exclude_labels: List[str] = ['exclude']) -> pd.DataFrame:
        """
        åŠ è¼‰æ¨™è¨»æ•¸æ“š

        Args:
            exclude_labels: æ’é™¤çš„æ¨™ç±¤é¡åˆ¥

        Returns:
            DataFrame
        """
        if not self.excel_a_path.exists():
            logger.error(f"âŒ Excel A ä¸å­˜åœ¨: {self.excel_a_path}")
            return pd.DataFrame()

        df = pd.read_excel(self.excel_a_path)
        logger.info(f"âœ… å·²åŠ è¼‰ {len(df)} æ¢æ¨™è¨»")

        # å…¼å®¹è™•ç†ï¼šæ”¯æŒèˆŠæ ¼å¼å’Œæ–°æ ¼å¼
        if 'åˆ¤å®šçµæœ' in df.columns:
            # æ–°æ ¼å¼ï¼ˆä¸­æ–‡åˆ—åï¼‰
            label_col = 'åˆ¤å®šçµæœ'
            # è½‰æ›ç‚ºå°å¯«ä»¥çµ±ä¸€è™•ç†
            df['label_lower'] = df[label_col].str.lower()
        else:
            # èˆŠæ ¼å¼ï¼ˆè‹±æ–‡åˆ—åï¼‰
            label_col = 'label'
            df['label_lower'] = df[label_col].str.lower()

        # éæ¿¾æ’é™¤é¡åˆ¥
        df_filtered = df[~df['label_lower'].isin([x.lower() for x in exclude_labels])]
        logger.info(f"   éæ¿¾å¾Œå‰©é¤˜ {len(df_filtered)} æ¢ï¼ˆæ’é™¤: {exclude_labels}ï¼‰")

        return df_filtered

    def get_download_tasks(self, df: pd.DataFrame) -> List[Dict]:
        """
        ç”Ÿæˆä¸‹è¼‰ä»»å‹™åˆ—è¡¨ï¼ˆå¢é‡ä¸‹è¼‰ï¼‰

        Args:
            df: æ¨™è¨»æ•¸æ“š

        Returns:
            ä¸‹è¼‰ä»»å‹™åˆ—è¡¨
        """
        tasks = []
        existing_files = set(self.download_dir.glob("*.mp4"))
        existing_ids = {f.stem.split('_')[-1] for f in existing_files}

        # å…¼å®¹è™•ç†ï¼šæ”¯æŒèˆŠæ ¼å¼å’Œæ–°æ ¼å¼
        url_col = 'å½±ç‰‡ç¶²å€' if 'å½±ç‰‡ç¶²å€' in df.columns else 'url'
        video_id_col = 'è¦–é »ID' if 'è¦–é »ID' in df.columns else 'video_id'
        author_col = 'ä½œè€…' if 'ä½œè€…' in df.columns else 'author'

        for _, row in df.iterrows():
            video_id = str(row[video_id_col])
            # ä½¿ç”¨çµ±ä¸€çš„ label_lower åˆ—
            label = row['label_lower']
            url = row[url_col]

            # æª¢æŸ¥æ˜¯å¦å·²ä¸‹è¼‰
            if video_id in existing_ids:
                continue

            # ç”Ÿæˆæ–‡ä»¶åï¼š{label}_{video_id}.mp4
            filename = f"{label}_{video_id}.mp4"
            filepath = self.download_dir / filename

            tasks.append({
                'url': url,
                'video_id': video_id,
                'label': label,
                'filepath': filepath,
                'author': row.get(author_col, 'unknown')
            })

        logger.info(f"ğŸ“¥ å¾…ä¸‹è¼‰: {len(tasks)} å€‹è¦–é »ï¼ˆå·²ä¸‹è¼‰: {len(existing_ids)}ï¼‰")
        return tasks

    def download_single_video(self, task: Dict) -> Dict:
        """
        ä¸‹è¼‰å–®å€‹è¦–é »

        Args:
            task: ä¸‹è¼‰ä»»å‹™

        Returns:
            çµæœå­—å…¸
        """
        url = task['url']
        filepath = task['filepath']
        video_id = task['video_id']

        for attempt in range(1, self.retry_times + 1):
            try:
                logger.info(f"â¬‡ï¸  ä¸‹è¼‰ä¸­: {video_id} (å˜—è©¦ {attempt}/{self.retry_times})")

                # ä½¿ç”¨ yt-dlp ä¸‹è¼‰
                cmd = [
                    'yt-dlp',
                    '-o', str(filepath),
                    '--quiet',
                    '--no-warnings',
                    url
                ]

                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=120  # 2åˆ†é˜è¶…æ™‚
                )

                if result.returncode == 0 and filepath.exists():
                    file_size = filepath.stat().st_size / (1024 * 1024)  # MB
                    logger.info(f"âœ… ä¸‹è¼‰æˆåŠŸ: {video_id} ({file_size:.2f} MB)")
                    return {
                        'status': 'success',
                        'video_id': video_id,
                        'filepath': str(filepath),
                        'file_size_mb': file_size
                    }
                else:
                    error_msg = result.stderr if result.stderr else "æœªçŸ¥éŒ¯èª¤"
                    logger.warning(f"âš ï¸  ä¸‹è¼‰å¤±æ•—: {video_id} | {error_msg}")

            except subprocess.TimeoutExpired:
                logger.warning(f"â±ï¸  è¶…æ™‚: {video_id}")
            except Exception as e:
                logger.error(f"âŒ ç•°å¸¸: {video_id} | {e}")

            # é‡è©¦å‰ç­‰å¾…
            if attempt < self.retry_times:
                time.sleep(2)

        # æ‰€æœ‰å˜—è©¦å¤±æ•—
        return {
            'status': 'failed',
            'video_id': video_id,
            'error': f'é‡è©¦ {self.retry_times} æ¬¡å¾Œä»å¤±æ•—'
        }

    def batch_download(self, tasks: List[Dict]) -> Dict:
        """
        æ‰¹é‡ä¸‹è¼‰è¦–é »

        Args:
            tasks: ä¸‹è¼‰ä»»å‹™åˆ—è¡¨

        Returns:
            çµ±è¨ˆçµæœ
        """
        if not tasks:
            logger.info("âœ… ç„¡éœ€ä¸‹è¼‰")
            return {'success': 0, 'failed': 0}

        logger.info(f"ğŸš€ é–‹å§‹æ‰¹é‡ä¸‹è¼‰: {len(tasks)} å€‹è¦–é »ï¼ˆä¸¦è¡Œæ•¸: {self.max_workers}ï¼‰")

        success_count = 0
        failed_count = 0
        failed_videos = []

        # ä¸¦è¡Œä¸‹è¼‰
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {executor.submit(self.download_single_video, task): task for task in tasks}

            for future in as_completed(futures):
                result = future.result()
                if result['status'] == 'success':
                    success_count += 1
                else:
                    failed_count += 1
                    failed_videos.append(result['video_id'])

        logger.info(f"\n{'='*80}")
        logger.info(f"ä¸‹è¼‰å®Œæˆ:")
        logger.info(f"  âœ… æˆåŠŸ: {success_count}")
        logger.info(f"  âŒ å¤±æ•—: {failed_count}")
        if failed_videos:
            logger.info(f"  å¤±æ•—åˆ—è¡¨: {', '.join(failed_videos)}")
        logger.info(f"{'='*80}\n")

        return {
            'success': success_count,
            'failed': failed_count,
            'failed_videos': failed_videos
        }

    def download_from_excel_a(self, exclude_labels: List[str] = ['exclude']) -> Dict:
        """
        å®Œæ•´æµç¨‹ï¼šå¾Excel Aä¸‹è¼‰è¦–é »

        Args:
            exclude_labels: æ’é™¤çš„æ¨™ç±¤é¡åˆ¥

        Returns:
            çµ±è¨ˆçµæœ
        """
        # 1. åŠ è¼‰æ¨™è¨»
        df = self.load_labels(exclude_labels)
        if df.empty:
            return {'success': 0, 'failed': 0}

        # 2. ç”Ÿæˆä¸‹è¼‰ä»»å‹™
        tasks = self.get_download_tasks(df)

        # 3. æ‰¹é‡ä¸‹è¼‰
        stats = self.batch_download(tasks)

        return stats


def main():
    """æ¸¬è©¦ä¸‹è¼‰å™¨"""
    import argparse

    parser = argparse.ArgumentParser(description="TikTokè¦–é »æ‰¹é‡ä¸‹è¼‰å™¨")
    parser.add_argument(
        '--excel-a',
        type=str,
        default='../../data/tiktok_labels/excel_a_labels_raw.xlsx',
        help='Excel A è·¯å¾‘'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='../../data/tiktok_videos',
        help='ä¸‹è¼‰ç›®éŒ„'
    )
    parser.add_argument(
        '--workers',
        type=int,
        default=4,
        help='ä¸¦è¡Œä¸‹è¼‰æ•¸'
    )
    parser.add_argument(
        '--include-exclude',
        action='store_true',
        help='åŒ…å« exclude é¡åˆ¥ï¼ˆé›»å½±/å‹•ç•«ï¼‰'
    )

    args = parser.parse_args()

    # å‰µå»ºä¸‹è¼‰å™¨
    downloader = TikTokDownloader(
        excel_a_path=args.excel_a,
        download_dir=args.output,
        max_workers=args.workers
    )

    # åŸ·è¡Œä¸‹è¼‰
    exclude_labels = [] if args.include_exclude else ['exclude']
    stats = downloader.download_from_excel_a(exclude_labels=exclude_labels)

    print(f"\nâœ… ä¸‹è¼‰ä»»å‹™å®Œæˆï¼")
    print(f"   æˆåŠŸ: {stats['success']} å€‹")
    print(f"   å¤±æ•—: {stats['failed']} å€‹")


if __name__ == "__main__":
    main()
