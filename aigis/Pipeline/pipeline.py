#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Aigis Pipeline - å¤œé–“è‡ªå‹•åŒ–ETL + ä¸»å‹•å­¸ç¿’
ç¬¬ä¸€æ€§åŸç†ï¼šç¡è¦ºæ™‚è¨“ç·´ï¼Œé†’ä¾†æ™‚æ”¶ç©«
"""

import os
import sys
import subprocess
import pandas as pd
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)

# === é…ç½® ===
BASE_DIR = Path(__file__).parent
DATASET_FILE = BASE_DIR.parent / "TikTok_Labeler_Server" / "dataset.csv"
DOWNLOAD_DIR = BASE_DIR / "downloaded_videos"
FEATURES_FILE = BASE_DIR / "features_matrix.csv"
MODEL_FILE = BASE_DIR / "model_latest.json"

# è—éšŠæ¨¡çµ„è·¯å¾‘
BLUE_TEAM_DIR = BASE_DIR.parent.parent / "modules"

def phase_1_download():
    """
    Phase 1: ä¸‹è¼‰è¦–é »

    æ²™çš‡ç‚¸å½ˆï¼šå¢é‡ä¸‹è¼‰ï¼ˆåªä¸‹è¼‰æ–°å¢ï¼‰
    """
    logging.info("ğŸ“¥ [Phase 1] ä¸‹è¼‰è¦–é »ä¸­...")

    if not DATASET_FILE.exists():
        logging.error("âŒ dataset.csv ä¸å­˜åœ¨ï¼Œè«‹å…ˆæ¨™è¨»æ•¸æ“š")
        return

    df = pd.read_csv(DATASET_FILE)
    urls = df['video_url'].unique()

    # è¨ˆç®—å¢é‡
    existing_files = set(DOWNLOAD_DIR.glob("*.mp4"))
    existing_ids = {f.stem for f in existing_files}

    to_download = []
    for url in urls:
        video_id = url.split('/')[-1].split('?')[0]
        if video_id not in existing_ids:
            to_download.append(url)

    if not to_download:
        logging.info("âœ… æ‰€æœ‰è¦–é »å·²ä¸‹è¼‰")
        return

    logging.info(f"ğŸ“¥ éœ€ä¸‹è¼‰ {len(to_download)} å€‹è¦–é »...")

    # ä½¿ç”¨yt-dlpä¸‹è¼‰
    for i, url in enumerate(to_download):
        try:
            subprocess.run([
                "yt-dlp",
                "-o", str(DOWNLOAD_DIR / "%(id)s.%(ext)s"),
                url
            ], check=True, capture_output=True)
            logging.info(f"  [{i+1}/{len(to_download)}] âœ“")
        except Exception as e:
            logging.error(f"  [{i+1}/{len(to_download)}] âœ— {e}")

    logging.info("âœ… ä¸‹è¼‰å®Œæˆ")

def phase_2_extract():
    """
    Phase 2: ç‰¹å¾µæå–

    çŒ›ç¦½3ï¼šä¸¦è¡ŒåŒ–è™•ç†ï¼ˆæœªä¾†å„ªåŒ–ï¼‰
    """
    logging.info("ğŸ”¬ [Phase 2] ç‰¹å¾µæå–ä¸­...")

    # åŠ è¼‰æ¨™è¨»
    df_labels = pd.read_csv(DATASET_FILE)

    # åŠ è¼‰å·²æœ‰ç‰¹å¾µï¼ˆå¢é‡ï¼‰
    if FEATURES_FILE.exists():
        df_features = pd.read_csv(FEATURES_FILE)
        processed_ids = set(df_features['video_id'])
    else:
        df_features = pd.DataFrame()
        processed_ids = set()

    # è¨ˆç®—å¢é‡
    video_files = list(DOWNLOAD_DIR.glob("*.mp4"))
    new_files = [f for f in video_files if f.stem not in processed_ids]

    if not new_files:
        logging.info("âœ… æ‰€æœ‰è¦–é »å·²æå–ç‰¹å¾µ")
        return

    logging.info(f"ğŸ”¬ éœ€æå– {len(new_files)} å€‹è¦–é »...")

    # TODO: èª¿ç”¨è—éšŠ12æ¨¡çµ„
    # æš«æ™‚è¿”å›éš¨æ©Ÿç‰¹å¾µ
    logging.warning("âš ï¸ ç‰¹å¾µæå–æœªå¯¦ç¾ï¼Œè«‹æ‰‹å‹•é›†æˆè—éšŠæ¨¡çµ„")

def phase_3_train():
    """
    Phase 3: æ¨¡å‹è¨“ç·´

    æ²™çš‡ç‚¸å½ˆï¼šXGBoost + ä¸»å‹•å­¸ç¿’
    """
    logging.info("ğŸ§  [Phase 3] æ¨¡å‹è¨“ç·´ä¸­...")

    if not FEATURES_FILE.exists():
        logging.error("âŒ features_matrix.csv ä¸å­˜åœ¨")
        return

    # TODO: XGBoostè¨“ç·´
    logging.warning("âš ï¸ æ¨¡å‹è¨“ç·´æœªå¯¦ç¾")

def main():
    """ä¸»æµç¨‹"""
    logging.info("ğŸš€ Aigis Pipeline å•Ÿå‹•")

    phase_1_download()
    phase_2_extract()
    phase_3_train()

    logging.info("âœ… Pipeline å®Œæˆ")

if __name__ == "__main__":
    main()
